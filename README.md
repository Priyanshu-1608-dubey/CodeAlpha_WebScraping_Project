## Web Scraping and Data Visualization Project

ğŸ“Œ Project Overview

This project focuses on automated data extraction from public web pages using Python-based web scraping techniques. The system collects relevant information from websites, processes it into a structured dataset, and visualizes the extracted data through an interactive user interface dashboard.

The project demonstrates practical implementation of web scraping, data handling, and visualization techniques commonly used in real-world data analysis applications.

# ğŸ¯ Objectives

To automatically extract structured data from public websites

To understand and handle HTML structure for accurate data collection

To create custom datasets tailored for analysis purposes

To visualize scraped data using an interactive UI dashboard

# ğŸ› ï¸ Technologies & Tools Used

Python â€“ Core programming language

BeautifulSoup â€“ HTML parsing and data extraction

Requests â€“ Sending HTTP requests to web pages

Pandas â€“ Data processing and dataset creation

Streamlit â€“ Interactive UI dashboard for data visualization

# âš™ï¸ System Workflow

Send HTTP requests to the target public website

Parse the HTML content using BeautifulSoup

Extract relevant data elements from the web page

Store the extracted data in CSV format

Load the dataset into Streamlit

Display and analyze the data using a web-based dashboard

# ğŸ“‚ Project Features

Automated web data collection

Structured CSV dataset generation

Interactive and user-friendly dashboard

Modular and scalable project architecture

# ğŸ“Š Output

CSV Dataset containing scraped web data

Interactive UI Dashboard for data visualization and analysis

# ğŸ”— GitHub Repository

The complete source code for this project is available on GitHub:

# ğŸ‘‰ GitHub Profile:

https://github.com/Priyanshu-1608-dubey

# ğŸ“ Conclusion

This project successfully demonstrates the use of web scraping techniques to collect data from public websites and transform it into meaningful datasets. The addition of an interactive dashboard enhances data accessibility and usability, making the system suitable for academic and practical applications.

## How to Run the Project (Step-by-Step)

Follow the steps below to successfully run the web scraping project and view the UI dashboard.

ğŸ”¹ Step 1: Clone or Download the Project

Download the project folder or clone it from GitHub.

git clone https://github.com/Priyanshu-1608-dubey

Or manually extract the project folder to your system.

ğŸ”¹ Step 2: Open Project Directory

Open Command Prompt / PowerShell and navigate to the project folder:

cd web_scraping_project

ğŸ”¹ Step 3: Install Required Python Libraries

Make sure Python is installed. Then install the required dependencies:

pip install requests beautifulsoup4 pandas streamlit

# âš ï¸ If multiple Python versions are installed, use:

py -m pip install requests beautifulsoup4 pandas streamlit

ğŸ”¹ Step 4: Run the Web Scraping Script

Execute the scraping script to extract data and generate the dataset:

py scraper/scrape_quotes.py

# âœ… This will create a CSV file inside the data/ folder.

ğŸ”¹ Step 5: Run the Streamlit UI Dashboard

Start the interactive dashboard using the following command:

py -m streamlit run dashboard/app.py

ğŸ”¹ Step 6: View Output in Browser
